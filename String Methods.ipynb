{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "763a368e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee Duration Discount\n",
      "0    SPARK  22000   30days     1000\n",
      "1  PYSPARK  25000   50days     2300\n",
      "2   HADOOP  24000   40days     2500\n",
      "3   PANDAS  26000   60days     1400\n",
      "\n",
      "\n",
      "   Courses    Fee Duration Discount\n",
      "0    spark  22000   30days     1000\n",
      "1  pyspark  25000   50days     2300\n",
      "2   hadoop  24000   40days     2500\n",
      "3   pandas  26000   60days     1400\n",
      "   Courses    Fee Duration Discount\n",
      "0    spark  22000   30days     1000\n",
      "1  pyspark  25000   50days     2300\n",
      "2   hadoop  24000   40days     2500\n",
      "3   pandas  26000   60days     1400\n",
      "   Courses    Fee Duration Discount\n",
      "0    spark  22000   30days     1000\n",
      "1  pyspark  25000   50days     2300\n",
      "2   hadoop  24000   40days     2500\n",
      "3   pandas  26000   60days     1400\n",
      "   Courses    Fee Duration Discount\n",
      "0    spark  22000   30days     1000\n",
      "1  pyspark  25000   50days     2300\n",
      "2   hadoop  24000   40days     2500\n",
      "3   pandas  26000   60days     1400\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "technologies= ({\n",
    "    'Courses':[\"SPARK\",\"PYSPARK\",\"HADOOP\",\"PANDAS\"],\n",
    "    'Fee' :['22000','25000','24000','26000'],\n",
    "    'Duration':['30days','50days','40days','60days'],\n",
    "    'Discount':['1000','2300','2500','1400']\n",
    "              })\n",
    "df = pd.DataFrame(technologies)\n",
    "print(df)\n",
    "\n",
    "# convert lowercase column use str.lower()\n",
    "df['Courses'] = df['Courses'].str.lower()\n",
    "print(df)\n",
    "\n",
    "# convert lowercase column use apply()\n",
    "df['Courses'] = df['Courses'].apply(str.lower)\n",
    "print(df)\n",
    "\n",
    "# Use apply() & lambda function\n",
    "df['Courses'].apply(lambda x: x.lower())\n",
    "print(df)\n",
    "\n",
    "# Convert pandas column to lowercase use map()\n",
    "df['Courses'] = df['Courses'].map(str.lower)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce39e645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6\n",
       "1    8\n",
       "2    7\n",
       "3    8\n",
       "4    8\n",
       "Name: name, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "technologies= ({\n",
    "    'Courses':[\"SPARK\",\"PYSPARK\",\"HADOOP\",\"PANDAS\"],\n",
    "    'Fee' :['22000','25000','24000','26000'],\n",
    "    'Duration':['30days','50days','40days','60days'],\n",
    "    'Discount':['1000','2300','2500','1400']\n",
    "})\n",
    "df = pd.DataFrame(technologies)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.DataFrame({\n",
    "    'age' : [15, 17, 20, 14, 25],\n",
    "    'name': [\"Sample\", \"New User\", \"My Name\", \"Jane Doe\", \"John Doe\"]\n",
    "})\n",
    "data['name'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1b961c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1. Bat.\n",
       "1    2. Dog!\n",
       "2    3. fox?\n",
       "3        NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "s = pd.Series(['1. Bat.  ', '2. Dog!\\n', '3. fox?\\t', np.nan])\n",
    "s.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50a8cebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         [this, is, my, new, pen]\n",
       "1    [https://www.w3resource.com/pandas/index.php]\n",
       "2                                              NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "s = pd.Series([\"this is my new pen\",\"https://www.w3resource.com/pandas/index.php\",np.nan])\n",
    "s.str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10c00a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee Duration Discount Courses_split\n",
      "0    spark  22000   30days     1000       [spark]\n",
      "1  pyspark  25000   50days     2300     [pyspark]\n",
      "2   hadoop  24000   40days     2500      [hadoop]\n",
      "3   pandas  26000   60days     1400      [pandas]\n"
     ]
    }
   ],
   "source": [
    "# str.split()\n",
    "df['Courses_split'] = df['Courses'].str.split()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c49ae3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee Duration Discount Courses_split  Contains_SP\n",
      "0    spark  22000   30days     1000       [spark]        False\n",
      "1  pyspark  25000   50days     2300     [pyspark]        False\n",
      "2   hadoop  24000   40days     2500      [hadoop]        False\n",
      "3   pandas  26000   60days     1400      [pandas]        False\n"
     ]
    }
   ],
   "source": [
    "# str.contains()\n",
    "df['Contains_SP'] = df['Courses'].str.contains('SP')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "526c0ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee Duration Discount Courses_split  Contains_SP  \\\n",
      "0    spark  22000   30days     1000       [spark]        False   \n",
      "1  pyspark  25000   50days     2300     [pyspark]        False   \n",
      "2   hadoop  24000   40days     2500      [hadoop]        False   \n",
      "3   pandas  26000   60days     1400      [pandas]        False   \n",
      "\n",
      "  Duration_replace  \n",
      "0               30  \n",
      "1               50  \n",
      "2               40  \n",
      "3               60  \n"
     ]
    }
   ],
   "source": [
    "# str.replace()\n",
    "df['Duration_replace'] = df['Duration'].str.replace('days', '')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccee3eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee Duration Discount Courses_split  Contains_SP  \\\n",
      "0    spark  22000   30days     1000       [spark]        False   \n",
      "1  pyspark  25000   50days     2300     [pyspark]        False   \n",
      "2   hadoop  24000   40days     2500      [hadoop]        False   \n",
      "3   pandas  26000   60days     1400      [pandas]        False   \n",
      "\n",
      "  Duration_replace  Startswith_P  \n",
      "0               30         False  \n",
      "1               50         False  \n",
      "2               40         False  \n",
      "3               60         False  \n"
     ]
    }
   ],
   "source": [
    "# str.startswith()\n",
    "df['Startswith_P'] = df['Courses'].str.startswith('P')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36816c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee Duration Discount Courses_split  Contains_SP  \\\n",
      "0    spark  22000   30days     1000       [spark]        False   \n",
      "1  pyspark  25000   50days     2300     [pyspark]        False   \n",
      "2   hadoop  24000   40days     2500      [hadoop]        False   \n",
      "3   pandas  26000   60days     1400      [pandas]        False   \n",
      "\n",
      "  Duration_replace  Startswith_P  Endswith_KS  \n",
      "0               30         False        False  \n",
      "1               50         False        False  \n",
      "2               40         False        False  \n",
      "3               60         False        False  \n"
     ]
    }
   ],
   "source": [
    "# str.endswith()\n",
    "df['Endswith_KS'] = df['Courses'].str.endswith('KS')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2c8b943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee Duration Discount Courses_split  Contains_SP  \\\n",
      "0    spark  22000   30days     1000       [spark]        False   \n",
      "1  pyspark  25000   50days     2300     [pyspark]        False   \n",
      "2   hadoop  24000   40days     2500      [hadoop]        False   \n",
      "3   pandas  26000   60days     1400      [pandas]        False   \n",
      "\n",
      "  Duration_replace  Startswith_P  Endswith_KS    Concatenated  \n",
      "0               30         False        False    spark_30days  \n",
      "1               50         False        False  pyspark_50days  \n",
      "2               40         False        False   hadoop_40days  \n",
      "3               60         False        False   pandas_60days  \n"
     ]
    }
   ],
   "source": [
    "# str.cat()\n",
    "df['Concatenated'] = df['Courses'].str.cat(df['Duration'], sep='_')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d33ad1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee Duration Discount Courses_split  Contains_SP  \\\n",
      "0    spark  22000   30days     1000       [spark]        False   \n",
      "1  pyspark  25000   50days     2300     [pyspark]        False   \n",
      "2   hadoop  24000   40days     2500      [hadoop]        False   \n",
      "3   pandas  26000   60days     1400      [pandas]        False   \n",
      "\n",
      "  Duration_replace  Startswith_P  Endswith_KS    Concatenated First_letter  \n",
      "0               30         False        False    spark_30days            s  \n",
      "1               50         False        False  pyspark_50days            p  \n",
      "2               40         False        False   hadoop_40days            h  \n",
      "3               60         False        False   pandas_60days            p  \n"
     ]
    }
   ],
   "source": [
    "# str.get()\n",
    "df['First_letter'] = df['Courses'].str.get(0)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "767e1804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee Duration Discount Courses_split  Contains_SP  \\\n",
      "0    spark  22000   30days     1000       [spark]        False   \n",
      "1  pyspark  25000   50days     2300     [pyspark]        False   \n",
      "2   hadoop  24000   40days     2500      [hadoop]        False   \n",
      "3   pandas  26000   60days     1400      [pandas]        False   \n",
      "\n",
      "  Duration_replace  Startswith_P  Endswith_KS    Concatenated First_letter  \n",
      "0               30         False        False    spark_30days            p  \n",
      "1               50         False        False  pyspark_50days            y  \n",
      "2               40         False        False   hadoop_40days            a  \n",
      "3               60         False        False   pandas_60days            a  \n"
     ]
    }
   ],
   "source": [
    "# str.get()\n",
    "df['First_letter'] = df['Courses'].str.get(1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0c76375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee Duration Discount Courses_split  Contains_SP  \\\n",
      "0    spark  22000   30days     1000       [spark]        False   \n",
      "1  pyspark  25000   50days     2300     [pyspark]        False   \n",
      "2   hadoop  24000   40days     2500      [hadoop]        False   \n",
      "3   pandas  26000   60days     1400      [pandas]        False   \n",
      "\n",
      "  Duration_replace  Startswith_P  Endswith_KS    Concatenated First_letter  \\\n",
      "0               30         False        False    spark_30days            p   \n",
      "1               50         False        False  pyspark_50days            y   \n",
      "2               40         False        False   hadoop_40days            a   \n",
      "3               60         False        False   pandas_60days            a   \n",
      "\n",
      "  Sliced  \n",
      "0     pa  \n",
      "1     ys  \n",
      "2     ad  \n",
      "3     an  \n"
     ]
    }
   ],
   "source": [
    "# str.slice()\n",
    "df['Sliced'] = df['Courses'].str.slice(1, 3)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aba5c03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee Duration Discount Courses_split  Contains_SP  \\\n",
      "0    spark  22000   30days     1000       [spark]        False   \n",
      "1  pyspark  25000   50days     2300     [pyspark]        False   \n",
      "2   hadoop  24000   40days     2500      [hadoop]        False   \n",
      "3   pandas  26000   60days     1400      [pandas]        False   \n",
      "\n",
      "  Duration_replace  Startswith_P  Endswith_KS    Concatenated First_letter  \\\n",
      "0               30         False        False    spark_30days            p   \n",
      "1               50         False        False  pyspark_50days            y   \n",
      "2               40         False        False   hadoop_40days            a   \n",
      "3               60         False        False   pandas_60days            a   \n",
      "\n",
      "  Sliced  Find_A  \n",
      "0     pa      -1  \n",
      "1     ys      -1  \n",
      "2     ad      -1  \n",
      "3     an      -1  \n"
     ]
    }
   ],
   "source": [
    "# str.find()\n",
    "df['Find_A'] = df['Courses'].str.find('A')\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
